## HTTP configuration
%dev.quarkus.http.port=8092
# random port for testing
quarkus.http.test-port=0

quarkus.http.cors=true
quarkus.http.cors.origins=*


#<aiProps>
quarkus.langchain4j.openai.base-url=${LLM_API_ENDPOINT:https://granite-7b-instruct-llm.apps.llm.sandbox2463.opentlc.com/v1/chat/completions}
quarkus.langchain4j.openai.chat-model.model-name=${LLM_MODEL:granite-7b-instruct}
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY:none}
quarkus.langchain4j.openai.chat-model.temperature=1
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
quarkus.langchain4j.openai.timeout=60s
#</aiProps>